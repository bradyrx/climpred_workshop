{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2D Tutorial: Reproduce Fig. 2 of Yeager et al. 2018\n",
    "\n",
    "This `climpred` lesson analyzes CESM-DPLE SST forecasts to recreate a portion of Figure. 2 from Yeager et al. 2018\n",
    "\n",
    "![](https://i.imgur.com/y6RJE6E.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import climpred\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally not good practice, but we want to supress errors related\n",
    "# to having NaNs on the grid.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in CESM-DPLE and ERSSTv5\n",
    "\n",
    "---\n",
    "\n",
    "Note that I pre-processed the CESM-DPLE this by taking the ensemble mean globally to avoid the time it would take to compute live in a workshop. Using `dask_jobqueue` with a few nodes of workers, this only took a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/glade/work/rbrady/workshops/climpred/CESM-DP-LE.SST.annmean.ensmean.nc'\n",
    "hind = xr.open_dataset(filepath)\n",
    "print(hind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename to the dimension conventions from `climpred`. The package expects at the least a `lead` dimension and `init` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind = hind.rename({'L': 'lead', 'S': 'init'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the `init` dimension to accurately reflect the initialization year. The post-processed output available on Cheyenne uses the convention `S` = 1955 for a November 1954 initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind['init'] = hind['init'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the ERSSTv5 monthly mean observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/glade/work/rbrady/workshops/climpred/ERSSTv5.mnmean.nc'\n",
    "obs = xr.open_dataset(filepath)\n",
    "obs = obs.rename({'sst': 'SST'})  # Matches variable name in CESM-DPLE\n",
    "obs = obs.drop_vars(['time_bnds'])\n",
    "obs.attrs = ''\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert observations to annual means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs.groupby('time.year').mean('time').rename({'year': 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate anomalies by subtracting climatology period used in bias-correcting CESM-DPLE (1964-2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs - obs.sel(time=slice(1964, 2014)).mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrid Products to 5x5 Grid\n",
    "\n",
    "---\n",
    "\n",
    "This is done using an external package called `xesmf`, which wraps ESMF. `climpred` has a `smoothing` module that is still in development that will automate this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename dimensions for what `xesmf` expects.\n",
    "hind = hind.rename({'nlat': 'y',\n",
    "                    'nlon': 'x',\n",
    "                    'TLAT': 'lat',\n",
    "                    'TLONG': 'lon'})\n",
    "\n",
    "obs = obs.rename_dims({'lat': 'y', 'lon': 'x'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a target grid that is a rectilinear 5x5 degree mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_grid = xe.util.grid_global(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrid CESM-DPLE following `xesmf` procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(hind, target_grid, 'bilinear', periodic=True)\n",
    "hind_regridded = regridder(hind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(obs, target_grid, 'bilinear', periodic=True)\n",
    "obs_regridded = regridder(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a quick check with `xarray`'s native plotting methods to see that the regridded mesh looks as we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_regridded.SST.sel(time=1998).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Forecasts\n",
    "\n",
    "---\n",
    "\n",
    "We'll start out by replicating the first two rows of Fig. 2 from the Yeager BAMS paper without applying smoothing. `climpred` is still relatively early in development and does not handle datetime alignment for temporally smoothed persistence forecasts yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `HindcastEnsemble` object\n",
    "hindcast = climpred.HindcastEnsemble(hind_regridded)\n",
    "hindcast = hindcast.add_observations(obs_regridded, 'ERSST')\n",
    "print(hindcast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the forecasts against the ERSST observations by using the `.verify()` method. Strings for different metrics can be found here: https://climpred.readthedocs.io/en/latest/metrics.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_init = hindcast.verify(metric='acc')\n",
    "pval_init = hindcast.verify(metric='pval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC plots for individual years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 3 subplots as Robinson projections.\n",
    "f, axs = plt.subplots(ncols=3,\n",
    "                      subplot_kw=dict(projection=ccrs.Robinson()),\n",
    "                      figsize=(18, 10))\n",
    "\n",
    "# Loop through the three axes and leads 3, 5, and 7.\n",
    "for ax, lead in zip(axs.flatten(), [3, 5, 7]):\n",
    "\n",
    "    p = ax.pcolormesh(acc_init.lon,\n",
    "                     acc_init.lat,\n",
    "                     acc_init['SST'].sel(lead=lead),\n",
    "                     vmin=-1, vmax=1,  # Colorbar bounds.\n",
    "                     cmap='RdYlBu_r',\n",
    "                     transform=ccrs.PlateCarree()) # Transform needed to transform to Robinson projection.\n",
    "\n",
    "    # Only keep lon/lat with alpha of 0.10 for stippling.\n",
    "    lons = pval_init['lon'].where(pval_init['SST'] <= 0.10)\n",
    "    lats = pval_init['lat'].where(pval_init['SST'] <= 0.10)\n",
    "    ax.scatter(lons.sel(lead=lead),\n",
    "               lats.sel(lead=lead),\n",
    "               marker='.', s=1, color='k',\n",
    "               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    ax.add_feature(cfeature.LAND, color='k', zorder=4) # Add land and put on top layer\n",
    "    ax.set(title=f'Lead Year {lead}')\n",
    "\n",
    "f.tight_layout()\n",
    "# Makes one colorbar for the multiple subplots.\n",
    "f.colorbar(p, ax=axs.ravel().tolist(),\n",
    "           orientation='horizontal',\n",
    "           fraction=0.03, pad=0.05,\n",
    "           label='Anomaly Correlation Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta$ACC Plots for the same years\n",
    "\n",
    "---\n",
    "\n",
    "p values not included here since we didn't compute z-score significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reference ACC from persistence forecast.\n",
    "acc_ref = hindcast.compute_persistence(metric='acc')\n",
    "pval_ref = hindcast.compute_persistence(metric='pval')\n",
    "\n",
    "# Find delta ACC relative to persistence.\n",
    "deltaACC = acc_init - acc_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(ncols=3,\n",
    "                      subplot_kw=dict(projection=ccrs.Robinson()),\n",
    "                      figsize=(18,10))\n",
    "\n",
    "for ax, lead in zip(axs.flatten(), [3, 5, 7]):\n",
    "    p = ax.contourf(deltaACC.lon,\n",
    "                   deltaACC.lat,\n",
    "                   deltaACC.SST.sel(lead=lead),\n",
    "                   levels=np.arange(-0.5, 0.51, 0.05),\n",
    "                   cmap='RdYlBu_r', extend='both',\n",
    "                   transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.LAND, color='k', zorder=4)\n",
    "    ax.set(title=f'Lead Year {lead}')\n",
    "\n",
    "f.tight_layout()\n",
    "f.colorbar(p, ax=axs.ravel().tolist(),\n",
    "           orientation='horizontal',\n",
    "           fraction=0.03, pad=0.05,\n",
    "           label='$\\Delta$ACC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed Forecasts\n",
    "\n",
    "---\n",
    "\n",
    "Here, we compute the ACC and MSSS for temporally smoothed forecasts. We don't compute the persistence reference for the smoothed forecast, as that functionality is not yet supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We have to make direct calls to the temporal smoothing module, although this will be abstracted away into a method of the `HindcastEnsemble` class in a future version release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth in 5-year leads (LY1-5, 2-6, and so on.)\n",
    "hind_ts = climpred.smoothing.temporal_smoothing(hind_regridded, smooth_kws={'lead': 5}, rename_dim=False)\n",
    "obs_ts = climpred.smoothing.temporal_smoothing(obs_regridded, smooth_kws={'time': 5}, rename_dim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-instantiate the `HindcastEnsemble` object with the smoothed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcast = climpred.HindcastEnsemble(hind_ts)\n",
    "hindcast = hindcast.add_observations(obs_ts, 'ERSST')\n",
    "print(hindcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hindcast.verify(metric='acc')\n",
    "pval = hindcast.verify(metric='pval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call utility function to rename lead dimension to readable temporal averages, e.g. \"1-5\", \"2-6\". Again, this will be abstracted away in a future version release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = climpred.smoothing._reset_temporal_axis(acc, smooth_kws={'lead': 5})\n",
    "pval = climpred.smoothing._reset_temporal_axis(pval, smooth_kws={'lead': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot as in Fig. 2 a-c of Yeager et al. Note that we did not do the FDR test for field significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 3 subplots as Plate Carree projections.\n",
    "f, axs = plt.subplots(ncols=3,\n",
    "                      subplot_kw=dict(projection=ccrs.PlateCarree()),\n",
    "                      figsize=(18,10))\n",
    "\n",
    "# Loop through the three axes and leads 1-5, 3-7, and 5-9.\n",
    "for ax, lead in zip(axs.flatten(), ['1-5', '3-7', '5-9']):\n",
    "    p = ax.pcolormesh(acc.lon,\n",
    "                   acc.lat,\n",
    "                   acc.SST.sel(lead=lead),\n",
    "                   vmin=-1, vmax=1,  # Colorbar bounds.\n",
    "                   cmap='RdYlBu_r')\n",
    "    \n",
    "    # Only keep lon/lat with alpha of 0.10 for stippling.\n",
    "    lons = pval['lon'].where(pval['SST'] <= 0.10)\n",
    "    lats = pval['lat'].where(pval['SST'] <= 0.10)\n",
    "    ax.scatter(lons.sel(lead=lead),\n",
    "               lats.sel(lead=lead),\n",
    "               marker='.', s=1, color='k',\n",
    "               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    ax.add_feature(cfeature.LAND, color='k', zorder=4) # Add land and put on top layer.\n",
    "    ax.set(title=f'Lead Year {lead}')\n",
    "\n",
    "f.tight_layout()\n",
    "# Makes one colorbar for the multiple subplots.\n",
    "f.colorbar(p, ax=axs.ravel().tolist(),\n",
    "           orientation='horizontal',\n",
    "           fraction=0.03, pad=0.05,\n",
    "           label='Anomaly Correlation Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: FDR Test\n",
    "\n",
    "---\n",
    "\n",
    "We don't yet have field significance tests built into `climpred`, but here is a way you might implement it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We \"stack\" the three dimensions into one big dimension, since `multipletests` just expects a singular dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = pval.stack(grid=['x', 'y', 'lead']).SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a number of variables, but we just care about the corrected pvalues. Run `help(multipletests)` to see the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pval_corrected, _, _ = multipletests(pval, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `DataArray` matching the dimensions and coordinates of original `pval` DataArray, since `multipletests` returns a `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_p = xr.DataArray(pval_corrected, dims=pval.dims, coords=pval.coords)\n",
    "new_p = new_p.unstack('grid') # Unstack back to 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep lon/lat with alpha of 0.10 for stippling.\n",
    "lons = new_p.lon.where(new_p <= 0.1)\n",
    "lats = new_p.lat.where(new_p <= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 3 subplots as Plate Carree projections.\n",
    "f, axs = plt.subplots(ncols=3,\n",
    "                      subplot_kw=dict(projection=ccrs.PlateCarree()),\n",
    "                      figsize=(18,10))\n",
    "\n",
    "# Loop through the three axes and leads 1-5, 3-7, and 5-9.\n",
    "for ax, lead in zip(axs.flatten(), ['1-5', '3-7', '5-9']):\n",
    "    p = ax.pcolormesh(acc.lon,\n",
    "                   acc.lat,\n",
    "                   acc.SST.sel(lead=lead),\n",
    "                   vmin=-1, vmax=1,  # Colorbar bounds.\n",
    "                   cmap='RdYlBu_r')\n",
    "    ax.scatter(lons.sel(lead=lead),\n",
    "               lats.sel(lead=lead),\n",
    "               marker='.', s=1, color='k',\n",
    "               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    ax.add_feature(cfeature.LAND, color='k', zorder=4) # Add land and put on top layer.\n",
    "    ax.set(title=f'Lead Year {lead}')\n",
    "\n",
    "f.tight_layout()\n",
    "# Makes one colorbar for the multiple subplots.\n",
    "f.colorbar(p, ax=axs.ravel().tolist(),\n",
    "           orientation='horizontal',\n",
    "           fraction=0.03, pad=0.05,\n",
    "           label='Anomaly Correlation Coefficient')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-climpred-workshop]",
   "language": "python",
   "name": "conda-env-miniconda3-climpred-workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
